
# Architecture
arch: vgg19_cifar10

# ===== Dataset ===== #
data: /userhome/mydata/cifar10
set: Cifar10
name: baseline

# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 0.1

# ===== Network training config ===== #
epochs: 160
weight_decay: 0.0005 # Change this according to reported numbers in appendix
momentum: 0.9
batch_size: 256

# ===== Sparsity =========== #
conv_type: MySparseConv
prune_rate: 0
bn_type: LearnedBatchNorm
init: kaiming_normal
mode: fan_in
nonlinearity: relu
beta: 1


# ===== Hardware setup ===== #
workers: 20